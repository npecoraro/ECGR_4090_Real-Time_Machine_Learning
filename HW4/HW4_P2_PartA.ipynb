{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fecd7c2830>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch6/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {6:0, 7:1, 8:2, 9:3}\n",
    "class_names = ['frog', 'horse', 'ship', 'truck']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [6, 7, 8, 9]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [6, 7, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # ... <1>\n",
    "            nn.Linear(8 * 8 * 8, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18156, [432, 16, 1152, 8, 16384, 32, 128, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  # <1>\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):  # <2>\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:  # <3>\n",
    "            \n",
    "            outputs = model(imgs)  # <4>\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)  # <5>\n",
    "\n",
    "            optimizer.zero_grad()  # <6>\n",
    "            \n",
    "            loss.backward()  # <7>\n",
    "            \n",
    "            optimizer.step()  # <8>\n",
    "\n",
    "            loss_train += loss.item()  # <9>\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))  # <10>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-22 20:43:30.114424 Epoch 1, Training loss 1.107844937152375\n",
      "2021-04-22 20:44:05.654933 Epoch 10, Training loss 0.49361159321599113\n",
      "2021-04-22 20:44:45.002464 Epoch 20, Training loss 0.3615066132987269\n",
      "2021-04-22 20:45:24.536254 Epoch 30, Training loss 0.2753318743393444\n",
      "2021-04-22 20:46:05.145542 Epoch 40, Training loss 0.23039149611997908\n",
      "2021-04-22 20:46:45.322117 Epoch 50, Training loss 0.20082552035967002\n",
      "2021-04-22 20:47:25.409966 Epoch 60, Training loss 0.1783888639566807\n",
      "2021-04-22 20:48:05.465277 Epoch 70, Training loss 0.15822151807931284\n",
      "2021-04-22 20:48:47.482846 Epoch 80, Training loss 0.14138888007107253\n",
      "2021-04-22 20:49:30.489791 Epoch 90, Training loss 0.12569668812873647\n",
      "2021-04-22 20:50:12.103737 Epoch 100, Training loss 0.11134072039097834\n",
      "2021-04-22 20:50:51.293441 Epoch 110, Training loss 0.09729174429925676\n",
      "2021-04-22 20:51:30.875557 Epoch 120, Training loss 0.08569707531636706\n",
      "2021-04-22 20:52:10.601192 Epoch 130, Training loss 0.07448389226743303\n",
      "2021-04-22 20:52:49.911680 Epoch 140, Training loss 0.06658464988556723\n",
      "2021-04-22 20:53:29.025207 Epoch 150, Training loss 0.057866857169916075\n",
      "2021-04-22 20:54:08.261197 Epoch 160, Training loss 0.049702708912900274\n",
      "2021-04-22 20:54:48.190169 Epoch 170, Training loss 0.043843499191414816\n",
      "2021-04-22 20:55:26.231110 Epoch 180, Training loss 0.03800309574552856\n",
      "2021-04-22 20:56:05.369751 Epoch 190, Training loss 0.0325529983537956\n",
      "2021-04-22 20:56:43.820640 Epoch 200, Training loss 0.02941460460989763\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)  # <1>\n",
    "\n",
    "model = Net()  #  <2>\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
    "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
    "\n",
    "training_loop(  # <5>\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18156, [432, 16, 1152, 8, 16384, 32, 128, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numel_list = [p.numel()\n",
    "              for p in model.parameters()\n",
    "              if p.requires_grad == True]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.90\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
